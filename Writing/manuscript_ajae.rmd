---
title: "Title here"
output:
  officedown::rdocx_document:
    toc: false
  bookdown::pdf_document2:
    toc: no
    keep_tex: true
author: |
  | $^1$University of Nebraska Lincoln,  $^2$University of Nebraska Lincoln, $^3$University of Illinois
  | Mona Mousavi, Taro Mieno^[Corresponding author: tmieno2@unl.edu], David S. Bullock
abstract: |
  Your abstract goes here...
bibliography: my_references.bib
#csl: american-journal-of-agricultural-economics.csl
fontsize: 12pt
header-includes: 
  \usepackage{float} \floatplacement{figure}{H} 
  \newcommand{\beginsupplement}{\setcounter{table}{0}  \renewcommand{\thetable}{S\arabic{table}} \setcounter{figure}{0} \renewcommand{\thefigure}{S\arabic{figure}}}
  \usepackage{setspace}\doublespacing
  \usepackage{lineno}
  \linenumbers
---

```{r echo = F, cache = F, include = F}
library(knitr)
library(here)

library(tinytex)


opts_chunk$set(
  fig.align = "center",
  fig.retina = 5,
  warning = F,
  message = F,
  cache = FALSE,
  echo = F,
  error = T,
  fig.cap = T
)
```




```{r cache = F, include = F}
#--- packages ---#
library(data.table)
library(tidyverse)
library(officedown)
library(officer)
library(flextable)
library(stringr)
library(sf)
library(lfe)
library(modelsummary)
library(patchwork)
library(gridExtra)
library(patchwork)
library(flextable)
library(officer)
library(modelsummary)
library(tidyverse)
```



```{r figure_setup, cache = F, include=FALSE}
#* +++++++++++++++++++++++++++++++++++
#* Default figure setting
#* +++++++++++++++++++++++++++++++++++
theme_update(
  axis.title.x =
    element_text(
      size = 12, angle = 0, hjust = .5, vjust = -0.3, face = "plain"
    ),
  axis.title.y =
    element_text(
      size = 12, angle = 90, hjust = .5, vjust = .9, face = "plain"
    ),
  axis.text.x =
    element_text(
      size = 10, angle = 0, hjust = .5, vjust = 1.5, face = "plain"
    ),
  axis.text.y =
    element_text(
      size = 10, angle = 0, hjust = 1, vjust = 0, face = "plain"
    ),
  axis.ticks =
    element_line(
      size = 0.3, linetype = "solid"
    ),
  axis.ticks.length = unit(.15, "cm"),
  #--- legend ---#
  legend.text =
    element_text(
      size = 10, angle = 0, hjust = 0, vjust = 0, face = "plain"
    ),
  legend.title =
    element_text(
      size = 10, angle = 0, hjust = 0, vjust = 0, face = "plain"
    ),
  legend.key.size = unit(0.5, "cm"),
  #--- strip (for faceting) ---#
  strip.text = element_text(size = 10),
  #--- plot title ---#
  plot.title = element_text(family = "Times", face = "bold", size = 12),
  #--- margin ---#
  # plot.margin = margin(0, 0, 0, 0, "cm"),
  #--- panel ---#
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_blank(),
  panel.border = element_rect(fill = NA)
)
```

```{r packages}
library(patchwork)
library(flextable)
library(officer)
library(modelsummary)
library(tidyverse)
```

 
**Keywords**: 

**Acknowledgement**: This research was supported by ....

# Introduction

Introduction outline

I)	The importance of EONR estimation. (Citation-difficulties)
II)	The role of OFPE in EONR estimation.
III)	Yield based model selection. 
a.	Conceptional framework 
b.	Limitations
IV)	Objective: new proposed model selection

 The presence of nitrogen is crucial for corn yield productivity [@bullock1994quadratic], yet the dynamic nature and spatial variability of soil physical properties impose a major challenge to optimal nitrogen management. This complexity arises from the intricate spatio-temporal interactions that regulate both plant growth patterns and the cycling of nutrients within the soil. The difficulty mainly stems from the intricate biophysical interactions that affect soil nitrogen mineralization, crop absorption, and nitrogen loss; On top of this, the mechanisms of nitrogen transformation can vary significantly not just within fields, but also between fields, which further complicates the task [@ransom2020corn; @correndo2021assessing]. To cope with this complexity, farmers often apply excess nitrogen fertilizer, which reduces profitability and lead to environmental destruction by increasing the risk of nitrogen loss [@ransom2020corn; @wen2022optimizing]. However, by avoiding both over and under-application of nitrogen fertilizer, farmers can reduce their cost and mitigate the environmental consequences associated with nitrogen loss [@wen2022optimizing]. The economic optimal nitrogen (N) rate signifies a point at which further increments in nitrogen application do not substantially enhance crop yield, thus discouraging excessive nitrogen usage. Employing the appropriate nitrogen quantity leads to cost savings while concurrently yielding a favorable profit and optimizing nitrogen utilization or nitrogen use efficiency (NUE). NUE is a measure of how effectively plants utilize the nitrogen available to them from various sources, such as fertilizers, organic matter in the soil, and atmospheric deposition. [@puntel2016modeling; @wortmann2011nitrogen].
The consideration of optimal N input is crucial when formulating N recommendations, as it holds the potential to significantly enhance N use efficiency and crop yield, while concurrently mitigating adverse environmental impacts. When nitrogen is applied at rates higher than optimal for crop use, the losses through leaching increase rapidly.By applying nutrients based on the specific needs of plants, there is a possibility of enhancing the profitability for producers. However, the difficulty lies in interpreting the spatial variation in fields to determine the optimal application rates that maximize profitability without excessive fertilization [@puntel2016modeling; @malzer1996corn]. In conventional agriculture, the natural spatial variations within a field are disregarded, and the entire area is managed uniformly. Nevertheless, implementing uniformly spatial nitrogen management can result in economic and environmental inefficiencies [@fassa2022site]. Due to the spatial dependence of field characteristics, there is a variation in how crop yields respond to managed inputs across a field [@trevisan2021spatial]. Site specific management is a useful method for optimizing crop production by adjusting inputs based on the specific site characteristics with the aim of determining the appropriate N rate for each part of the field [@fassa2022site]. As an example, @malzer1996corn indicated that economic benefits of using N fertilizers differ significantly depending on the landscape. The possible financial gains from employing N management practices tailored to specific sites can range anywhere from $4 to $37 per acre. In this regard, on-farm precision experiments (OFPE) conducted on a large-scale can provide insight into how to effectively adjust input application rates based on spatial variability, ultimately leading to optimized outcomes [@trevisan2021spatial].
Taking into account that the EONR for a specific field and year remains unknown at the point of nitrogen application, it is important to use nitrogen fertilizer recommendation tools that accurately align with the optimal nitrogen rate. Yet determining the EONR for a specific field and year is not a straightforward process and requires a complex methodology including conducting on-farm research trials with candidate nitrogen rates and monitoring the corresponding yield responses. [@ransom2019statistical]. To estimate the site-specific economic optimum nitrogen rates that align with the actual EONRs for a particular field, a diverse range of tools and methodologies have been developed. These include yield goal-based N recommendations [@stanford1973rationale], where nitrogen requirements are determined based on yield goals. Other approaches to estimate EONR are remote sensing [@reussi2015using; @oliveira2013calibrating], which assesses crop health and nitrogen status using technology like satellite imagery; soil testing and nutrient analysis [@bundy1995soil], which identifies soil nutrient levels for tailored nitrogen application; and economic maximum return to N [@ransom2019statistical], optimizing nitrogen rates for maximum economic profitability.
Current nitrogen (N) management practices in agriculture have limitations, with traditional tools being time-consuming and overlooking differences in landscape attributes, including soil texture and organic matter content. Precision agriculture technologies offer potential improvements by matching N requirements within field zones, but predicting optimal N rates remains challenging due to variability [@puntel2016modeling].
Other approaches to estimate EONR are crop simulation models [@miao2006evaluating]. These models use data on crop growth, nitrogen uptake, and environmental conditions integrating soil, weather, and management factors into mathematical equations to simulate crop responses to different nitrogen rates. By running various scenarios, the model can estimate the economic optimum nitrogen rate that maximizes net returns [@qin2018application]. 
A different approach for calculating crop nitrogen (N) fertilizer recommendations involves using machine learning models, a subset of artificial intelligence in computer science. These models make the most of advanced computational capabilities to learn patterns directly from data, without relying on explicit programming. By autonomously extracting insights from the provided information, they excel at discerning complex relationships.Distinguishing machine learning from traditional statistical methods can be challenging due to subtle distinctions. One crucial difference lies in the number of input variables used by machine learning, which often exceeds the variables employed in conventional statistical approaches. Although some of these features may not have a direct correlation with the target variable, their combined impact is utilized to enhance predictive accuracy.Nonetheless, a potential concern in machine learning is overfitting, wherein the model becomes excessively tailored to the training data. Consequently, its performance on new, unseen data may suffer. To address this issue, machine learning employs regularization techniques and cross-validation procedures. These methods are designed to control the model's complexity and improve its ability to handle new data effectively [@qin2018application; @correndo2021assessing].
Several studies [@wang2021machine; @du2022corn] have investigated the integration of soil and weather properties into machine learning techniques for predicting crop yield. The underlying premise is that incorporating diverse data sources, such as soil and weather information, can enhance the accuracy of yield prediction and subsequently improve the recommended nitrogen (N) rate. The authors of these studies often select the machine learning method based on its performance in predicting yield rather than its ability to estimate the economically optimal nitrogen rate. Other studies, such as the work by @correndo2021assessing, centered on examining the impact of variable uncertainties in the algorithm; yet none of these studies have employed a methodology to identify the optimal model based on its performance for estimating the economic optimum nitrogen rate.
The selection of a model based solely on its yield prediction performance poses a significant challenge. 
Model selection is an essential element in the decision-making process and holds significant importance in machine learning and statistical modeling. Its primary purpose is to identify the most appropriate model that accurately represents a given dataset. When considering the estimation of economic optimal nitrogen rates, model selection continues to be a critical aspect of decision-making. The objective is to carefully choose the model that best enables the determination of the optimal nitrogen application rate for crop production. By engaging in model selection, researchers can assess and compare various models, each representing a distinct approach to estimating economic optimal nitrogen rates. The aim is to identify the model that most effectively captures the intricate relationships between nitrogen inputs and crop yield while considering economic factors. 
The correlation between EONR and the corresponding yield at EONR is found to be inconclusive and of low magnitude  [@morris2018strengths; @sawyer2006concepts; @vanotti1994alternative]. 
The precise estimation of EONR is intricately linked to the underlying nitrogen response in relation to crop yield, rather than relying solely on the accuracy of yield prediction. Stated differently, the accurate determination of EONR is contingent upon a comprehensive understanding of the causal impact of the treatment variable on crop yield, which provides the necessary information for precise EONR estimation. Building on the previous point, it is important to note that a model's effectiveness in predicting the yield level does not necessarily imply its suitability for estimating EONR. As a result, a model that exhibits high accuracy in yield level prediction may not necessarily be the most appropriate model for EONR estimation. 

Fertilizer recommendations have been primarily derived from field trials that assess how crops respond to different levels of fertilizer application. By collecting data from fertilizer studies, it becomes possible to fit the results to a variety of statistical models, then the most suitable model for a given cropping scenario will be chosen based on a thorough evaluation and selection process. As machine learning models are being increasingly utilized for model selection in the determination of the EONR, it is crucial that the selection process accurately mirrors the underlying method used to obtain EONR. Statistical inference and machine learning involve learning from data by fitting models to it. These models can be either parametric or nonparametric. However, if the model or method is not chosen appropriately, it can lead to inaccurate or misleading results. Therefore, selecting the right model or approach is crucial in obtaining reliable conclusions from the data which in turn leads us to an accurate EONR estimation. 
The primary aim of this study is to introduce a novel approach for model selection that is underpinned by causal relationships, in order to accurately estimate the economically optimal nitrogen rate via simulation. The proposed method hinges upon the use of local cross-validation on EONR to determine the ideal nitrogen level for a given site. This process aims to enhance the accuracy and reliability of EONR estimates, which are crucial for optimizing agricultural yields and minimizing economic costs.







`r run_pagebreak()`

# Materials and Methods: 

<br>



```{r, fig.id = "Diagram", fig.cap = "Diagram of simulation", fig.width = 7.5, dpi = 1500}
#knitr::include_graphics("D_updated.jpg")
knitr::include_graphics(here( "D_updated.jpg"))

```

<br>

+ outline:

1. Overview of Data Simulation
In this section, we provide an overview of the data simulation process. This involves generating synthetic data that resembles real-world data for the purpose of analysis.
2. Data Generation
We describe the process of generating the synthetic data used in our analysis. This includes specifying the parameters, distributions, and relationships that govern the data generation process.
3. ML Model Performance in Site-Specific EONR Estimation with Complete Dataset (strem 1)
3.1. Site-Specific EONRs Using S-Learner Approach with RF, BRF, Linear, and SE model
3.2. Site-Specific EONRs Using R-Learner Approach with Smooth CF Model
3.3. Ranking the ML models by their RMSE between estimated EONRs and true EONRs
4. Model Selection based on Local EONRs (stream 2)
4.1. GAM Estimated Local EONRs
4.2. Local EONRs Estimated by candidate ML Models
4.3. Ranking the ML models by their RMSE between estimated local EONRs and gam
estimated local EONRs
5. Model Selection based on yield prediction ability (stream 3)
5.1. Yield prediction using spatial folds
5.2. Ranking the ML models by their RMSE between predicted yield and true yield
6. Comparing the performance of local EONR-based model selection with yield prediction-
based model selection
6.1. Contrasting the ranking of models based on local EONR selection with models
trained on the entire dataset
6.2. Comparing the ranking of models based on yield prediction ability with models
trained on the entire dataset


+ explain our proposed model selection method in general (no specific model needs to be mentioned) 

To propose a precise method for accurately predicting the optimal nitrogen rate, our study employed a local EONR model selection approach. To implement this method, we employed spatial clustering splits to partition the dataset into spatial folds consisting of training and testing datasets. Within each spatial fold, we utilized machine learning models to estimate uniform EONRs and subsequently derived local EONRs. We compared the root mean square error (RMSE) of the predicted local EONR values against the local EONR values obtained from a trained Generalized Additive Model (GAM), ranking the models based on their RMSE compared to the GAM model. Moreover, to obtain the true EONR values, we trained ML models on the entire dataset and ranked them based on their RMSE against the actual EONR values. By comparing the rankings of local EONR values and true EONR values, we evaluated the performance of the local EONR model selection. Additionally, to assess the performance of our proposed method against the yield prediction model selection approach, we also conducted model selection based on yield prediction within the spatial folds. The subsequent sections provide a detailed explanation of the steps and procedures involved. 


## ML Model Performance in Site-Specific EONR Estimation with Complete Dataset (stream 1)

The dataset consisting of OFPE data from 500 fields was utilized to estimate the true site-specific EONR values. These values were considered as the estimated true values because the entire dataset was used for both training and testing in the prediction of site-specific EONRs. Later, these estimated values would be compared to the true EONRs, which were calculated as an integral part of the simulation process.

To estimate the true site-specific EONRs, our research employed two distinct approaches for training the machine learning (ML) models: the S-learner approach and the R-learner approach.


To estimate true EONRs using the S-learner, a consistent approach was employed for our candidate ML models, including Random Forest (RF), Boosted Regression Forest (BRF), linear, and Spatial Error (SE) models. This involved training the ML models using the complete dataset. Subsequently, the yield response function associated with each model was estimated using validation data, which encompassed the entire dataset in this context. Profits (${\hat{\pi}}_{im}$) were then computed for each model, and the nitrogen level that maximized profit was determined site specifically within the test dataset.

Suppose we have a set of variables, denoted as $\Omega_i$ ,which represents specific characteristics of the field. Each variable within $\Omega_i$ corresponds to an explanatory feature for a particular location or observation. Let ${\hat{g}}_{im}(N_j,\ \Omega)$ represent a yield response function estimated by one of the candidate ML models, with j representing the  N rates. The estimated yield response function for a specific variable $\Omega_i$ and nitrogen rate  $N_j$ within model m can be denoted as ${\hat{g}}_{im}(N_j,\ \Omega_i)$. To determine the site-specific EONRs we solve the following problem for all variables $\Omega_i$ within each model:

$$
\widehat{N}_i^{o p t}=\underset{N_j}{\operatorname{argmax}}\left(p \cdot \hat{g}_{i m}\left(N_j, \Omega_i\right)-w \cdot N_j\right)
$$

where p and w represent the prices of corn and N respectively. 

To estimate the true site-specific EONRs using the R-learner with a causal forest model, we utilized the entire dataset as the training dataset to predict treatment effects. Nitrogen was considered a factor variable and its application within a given field was categorized into $\alpha$ levels denoted as $(N_\alpha\ ,\ \alpha\ \in{1,\ 2,\ 3,...,l})$. The objective of our analysis was to estimate the changes in yield $(Y)$ resulting from changes in nitrogen rates, specifically from the lowest level $(N_1)$ to the remaining $l-1$ levels ${(N}_\alpha)$, using the validation data (the entire dataset in this context).
We obtained $l-1$ distinct values representing the yield changes caused by varying the nitrogen rate for each observation $\left(\Delta Y_{N_1 \rightarrow N_\alpha}\right)$ in the validation dataset. These yield changes were then treated as the dependent variable, while the nitrogen levels served as the explanatory variables. Subsequently, a GAM was trained for each observation, and yield response function was estimated. The site-specific optimal nitrogen rates were determined by solving the same optimization problem as in the S-learner approach.


There are variations in profit outcomes when estimating true site-specific EONRs using candidate ML models. To determine the profit deficits associated with each model, we establish reference points based on the true optimal yield and true optimal nitrogen levels. These reference values are derived through simulation and serve as benchmarks for comparison.
By contrasting the model-predicted profits with the reference points, we can quantitatively assess the disparities and evaluate the accuracy of the ML models in estimating EONRs. The profit deficit $\Delta \pi_i$ can be calculated as follows:

$$
\begin{gathered}
\Delta \pi_i=\hat{\pi}_{i m}-\pi_i \\
\hat{\pi}_{i m}=p \cdot \hat{g}_{i m}\left(N_j, \Omega_i\right)-w \cdot \widehat{N}_{i m}^{o p t} \\
\pi_i=P \cdot Y_i^{o p t}-W \cdot N_i^{o p t}
\end{gathered}
$$

Where ${\hat{\pi}}_{im}$ represents the estimated profit obtained from the ML model $(m)$ for each observation (i), $\pi_i$ represents the true profit, ${\hat{g}}_{im}(N_j,\ \Omega_i)$ represents the estimated yield response function for a specific nitrogen rate $(N_j)$ and other variables $(\Omega_i)$ within the ML model $(m)$, The term $w.{\hat{N}}_{im}^{opt}$ represents the cost of nitrogen application, where $w$ signifies the cost per unit of nitrogen, and ${\hat{N}}_{im}^{opt}$ denotes the estimated optimal nitrogen level within the ML $(m)$. 
In the true profit calculation formula, $Y_i^{opt}$  represents the true optimal yield and $N_i^{opt}$ represents the true variable rate optimal nitrogen. 
In each simulation round we then average profit deficit for each model $(m)$:
$$
\overline{\Delta \pi}_m=\frac{1}{1440} \sum_{i=1}^{1440} \Delta \pi_i
$$
### Ranking the candidate ML models by their RMSE between estimated EONRs and true EONRs

In order to determine the most accurate ML model for estimating site-specific EONRs, we compare the site-specific EONRs estimated by candidate ML models with the true EONRs. 
The evaluation of model performance is carried out using the Root Mean Square Error (RMSE) as a metric. Within each simulated round the RMSE of the estimated variable-rate optimal nitrogen for each model (m) is computed using the formula:
$$
R M S E \text { of estimated EONR }=\sqrt[2]{\frac{1}{1440} \sum_{i=1}^{1440}\left(\widehat{N}_{\text {im }}^{\text {opt }}-N_i^{\text {opt }}\right)^2}
$$
In this equation, ${\hat{N}}_{im}^{opt}$ represents the estimated site-specific optimal nitrogen level obtained from the machine learning model (m), while $N_i^{opt}$ represents the true optimal nitrogen level. 
This evaluation metric provides a quantitative measure of the deviation between the estimated EONR and the true EONR. The lower the RMSE value, the closer the estimated EONRs are to the true values, indicating better EONR predictive performance of the model.
After calculating the RMSE of the estimated site-specific EONRs for candidate ML model, the next step involves ranking these models based on these evaluation metrics.

## Model Selection based on Local EONRs (stream 2)

We propose a methodology for model selection based on the estimation of local EONRs values, which involves spatial cross-validation of local EONRs. The rationale behind estimating local EONRs is the absence of observed true site-specific EONRs. Moreover, this approach enhances the accuracy of EONR estimation and improves the generalizability of our model.

The whole data are divided into multiple folds in a spatially clustered manner. Autocorrelated data raises concerns about overfitting. Random sampling for train-test splits or cross-validation violates the assumption of independent and identically distributed (IID) samples. If nearby samples with similar features are included in different sets, the model can make more accurate predictions for those samples.To prevent this, grouping the data by area restricts the model from accessing information it should not have seen. Spatial cross-validation is exemplified as follows:


```{r fig.id = "fig-1", fig.cap = "spatial_illustration", fig.width = 5, fig.width = 4, dpi = 400}
pCorn <- 6.25 / 25.4 # $/kg
pN <- 1 / 0.453592 # $/kg

sim_data_1 <- readRDS(here::here("Shared/Data/SimData/sim_data_1.rds"))

whole_data <-
  sim_data_1[[2]][[1]] %>%
  # find true EONR
  .[, opt_N := (pN / pCorn - b1) / (2 * b2)] %>%
  .[, opt_N := pmin(Nk, opt_N)] %>%
  .[, opt_N := pmax(0, opt_N)]

train_test_split <- readRDS(here::here("Shared/Results/sim_results_num_repeats_5_num_folds_5/train_test_split.rds"))


data_sf <- st_as_sf(whole_data, coords = c("X", "Y"))

spatial_folds <-
  train_test_split %>%
  rowwise() %>%
  mutate(training_data = list(
    whole_data[aunit_id %in% training_ids, ]
  )) %>%
  mutate(test_data = list(
    whole_data[aunit_id %in% test_ids, ]
  )) %>%
  data.table() %>%
  .[, .(split_id, training_data, test_data)]



plot_combined_fold <- function(fold_number) {
  # Convert the training data to an sf object and add a "Type" column indicating "Train"
  sf_data_train <- st_as_sf(spatial_folds[[2]][[fold_number]])
  sf_data_train$Type <- "Train"
  
  # Convert the test data to an sf object and add a "Type" column indicating "Test"
  sf_data_test <- st_as_sf(spatial_folds[[3]][[fold_number]])
  sf_data_test$Type <- "Test"
  
  # Combine both datasets
  sf_data_combined <- rbind(sf_data_train, sf_data_test)
  
  # Create a plot with fold number as subtitle
  g_combined <- ggplot(data = sf_data_combined) +
    geom_sf(aes(fill = Type), color = "black") +
    scale_fill_manual(values = c("Train" = "blue", "Test" = "red")) +
    theme_void() +
    theme(legend.position = "none") +  # Remove legend for individual plots
    labs(subtitle = paste("Fold", fold_number), x = NULL, y = NULL)
  
  # Return the plot
  return(g_combined)
}

# Create a list to store all the plots
all_plots <- list()

# Call the function for each fold and store the plots in the list
for (fold in 1:10) {
  all_plots[[fold]] <- plot_combined_fold(fold)
}

# Combine and arrange all the plots in a 2x5 grid layout
final_plot <- wrap_plots(plotlist = all_plots, ncol = 2, nrow = 5)

# Add the legend to the final graph
legend_title <- "Data Type"
final_plot <- final_plot + 
  theme(legend.position = "bottom") +
  guides(fill = guide_legend(title = legend_title, override.aes = list(color = c("blue", "red"))))

# Print the final combined plot
print(final_plot)

```



After splitting our dataset (repeatedly) into training and test sets we then performed an analysis to identify the number of overlapping observations and excluded folds and repetitions that exhibited significant similarities. For instance, if we consider 5 folds and 5 repetitions, we initially have 25 splits. However, through our analysis, we identified and removed splits that were too similar to ensure the reliability of our analysis. As a result, we ended up with fewer than 25 splits. This technique enables us to assess the robustness and stability of the obtained clusters.
Within each fold, the test data was employed to train the GAM and estimate the yield response function. Subsequently, uniform EONRs were derived for that particular fold. These EONRs are referred to as the GAM-estimated local EONRs.
For each fold, we trained candidate ML models using the train data. Following that, we estimated site-specific EONRs for the observations in the test data. The estimated local EONRs obtained from both the GAM and the ML models were then compared and ranked using the RMSE metric.


### Estimate Local EONR Using GAM as a Proxy for True EONR

In the absence of true EONRs, we utilize estimated local EONRs derived from GAM as an approximation for the true values. The gam estimated local EONRs provide a reference point against which the performance of candidate ML models can be assessed during the subsequent model selection process. To obtain the GAM local EONRs, we train GAM using the validation data within each clustered split. Subsequently, the yield response function and corresponding profits for a sequence of nitrogen rates are estimated. This allows us to estimate the uniform EONR for each spatial split.

Let ${\hat{g}}_{j\varphi GAM}(N_j)$ represent the yield response function estimated by GAM for the sequence of nitrogen rates $N_j$ at split $\varphi$. In order to estimate gam local EONRs, we solve the following problem for every split $\varphi$:

$$
\widehat{N}_{\varphi\mathrm{GAM}}^{opt}=\underset{N_j}{\operatorname{argmax}}\left(p \cdot \hat{g}_{\mathrm{j} \varphi \mathrm{GAM}}\left(N_j\right)-w \cdot N_j\right)
$$


### Estimate Local EONRs Using the Candidate ML Models

Candidate ML models were trained using the train data specific to each split, denoted as $\varphi$. Following the estimation of yield response function and corresponding profit, the site-specific EONRs were estimated for each observation in the the test data within the split. 
 
Let ${\hat{g}}_{i\varphi m}(N_j,\ \Omega)$ represent the yield response function estimated by model $m$ for the nitrogen rates $N_j$ at split $\varphi$. The estimated yield response function for a specific variable $\Omega_i$ and nitrogen level $N_j$ within the split $\varphi$ and model $m$ can be denoted as ${\hat{g}}_{i\varphi m}(N_j,\ \Omega_i)$. 

We solve the following optimization problem to find site-specific EONRs for each test data and split $\varphi$, and model $m$: 
$$
\widehat{N}_{i \varphi\mathrm{m}}^{o p t}=\underset{N_j}{\operatorname{argmax}}\left(p \cdot \hat{g}_{i \varphi m}\left(N_j, \Omega_i\right)-w \cdot N_j\right)
$$

Then to obtain local EONRs, site-speicfic EONRs were averaged for each split:

$$
\widehat{\mathrm{N}}_{\varphi \mathrm{m}}^{\mathrm{opt}}=\frac{1}{\mathrm{n}} \sum_{i=1}^{\mathrm{n}} \widehat{\mathrm{N}}_{\mathrm{i} \varphi \mathrm{m}}^{\mathrm{opt}}
$$
which $n$ represents te number of observations and in each test data within each split.

### Ranking the ML models by their RMSE between estimated local EONRs and gam estimated local EONRs

In order to assess the performance of candidate ML models $m$, the RMSE between GAM estimated and ML estimated Local EONRs were calculated for each round of simulation:

$$
\text { RMSE of Local EONR Estimated by ML Model vs Local GAM EONR }=\sqrt[2]{\frac{1}\phi \sum_{{\varphi}=1}^\phi\left(\widehat{N}_{\varphi m}^{o p t}-\widehat{\mathrm{N}}_{\varphi \mathrm{GAM}}^{o p t}\right)^2}
$$

The above RMSE metric provides a measure of the dissimilarity between the local EONRs estimated by the ML model $m$ and the gam estimated local EONRs.

We then rank the ML models based on their respective RMSE values of the local EONRs. A lower RMSE indicates a better alignment between the model's estimates and the gam estimates. Thus, we rank the ML models that exhibit lower RMSE values as they demonstrate higher accuracy in predicting the local EONRs.

## Model Selection based on yield prediction ability (Stream 3)

The yield prediction capability is widely employed as a primary criterion for model selection by researchers. In our study, we also evaluate models based on their yield prediction capability and compare its performance with our model selection method in terms of accurately estimating EONRs.

Within each split $(\varphi)$, we employed training data to train candidate ML models except for the causal forest model, which is specifically designed to analyze treatment effects rather than predict yields. Subsequently, we utilized the test data from each split to predict the yield ${\widehat{\ Y}}_{i\varphi m}$.


In each simulation round, candidate ML models were ranked according to their RMSE between the estimated yield, denoted as ${\widehat{\ Y}}_{\varphi m}$, and the true yield ${{\ Y}}_{\varphi }$. The RMSE of the yield was computed using the following formula:

$$
\text { RMSE of Yield predicted by ML Model vs Actual Yield }=\sqrt[2]{\frac{1}{\phi} \sum_{\varphi=1}^\phi\left(\hat{Y}_{\varphi m}^{}-Y_{\varphi}\right)^2}
$$
where  
$$
\begin{aligned}
& \hat{Y}_{\varphi m}^{}=\frac{1}{\mathrm{n}} \sum_{\mathrm{i}=1}^{\mathrm{n}} \widehat{\mathrm{Y}}_{\mathrm{i} \varphi \mathrm{m}} \\
& \mathrm{Y}_{\varphi}=\frac{1}{\mathrm{n}} \sum_{\mathrm{i}=1}^{\mathrm{n}} \mathrm{Y}_{\mathrm{i} \varphi \mathrm{m}}
\end{aligned}
$$

## Comparing the performance of local EONR-based model selection with yield prediction-based model selection


Comparing local EONR-based model selection with yield prediction-based model selection provides insights into their respective effectiveness in selecting suitable models for estimating EONRs.

Our study evaluated the performance of two model selection methods, Local EONR and yield-based criteria, in estimating EONRs. We examined the consistency between the rankings of models selected using these criteria and the rankings based on estimated true EONR. This analysis was conducted for each simulation round, providing insights into the alignment between the model selection methods' rankings and the rankings derived from estimated true EONR across all simulations.

In addition, we calculated the profit loss associated with selecting the best model suggested by our model selection method and the yield-based model selection, compared to the true profit. To determine this, we employed the same approach as discussed in stream 1 of our study.


# Results and Discussions

## Ranking of candidate ML models based on estimation of site-specific EONRs

Please note that all the presented results are derived from a combination of 5-fold cross-validation with 5 repetitions, unless explicitly stated otherwise.


```{r fig.id = "fig-3", fig.cap = "Ranking of Models Based on Actual Performance in Predicting Site Specific EONR", fig.width = 4, fig.width = 6, dpi = 400, cache=FALSE}

sum_results_whole <- readRDS(here::here("Shared/Results/Mona_results/sum_results_whole.rds")) %>%
  data.table()


# Create a visualization for RMSE rank of site-specific predictions
rmse_rank_site_specific <- sum_results_whole[, .(N = sum(eonr_selected_true)), by = method] %>%
  ggplot() +
  geom_bar(aes(y = N, x = method), stat = "identity", fill = "#555555") +  # Custom color
  labs(x = "Methods", y = "Count") +  # Axes labels and plot title
  theme_minimal() +  # Clean and minimal theme
  theme(
    plot.title = element_text(face = "plain"),      # Regular font style for title
    axis.text.y = element_text(),                  # Default font style for y-axis labels
    axis.title = element_text(),                  # Default font style for axes titles
    legend.title = element_text(),                # Default font style for legend title
    legend.text = element_text()                  # Default font style for legend text
  )

print(rmse_rank_site_specific)
```
Figure \@ref(fig:fig-3) presents the evaluation of candidate ML models in estimating site-specific EONRs through 500 simulations. The figure highlights the frequency of model selection based on their ability to minimize the RMSE compared to the true EONR. In this scenario, ML models underwent training using the complete dataset. Following the estimation of EONR, a ranking of these models was conducted, considering their RMSE. The model achieving the closest RMSE value to the true EONR was assigned a rank of one, indicating its better performance in EONR prediction. 
We utilize the given case as a foundational benchmark. The intention is to propose a model selection methodology that can attain outcomes similar to those achieved in this particular case. 

The figure shows that the SE model was selected in 78% of the simulations, indicating its consistent performance in achieving the lowest RMSE when estimating site-specific EONR. The BRF model was chosen in 14% of cases, followed by the linear model at 7.6%. The CF model had a selection rate of 0.4%, while the RF model was not selected at all.

## The performance ranking of the model selected by our local-EONR-based approach and yield-based selection approach 

```{r fig.id = "fig-4", fig.cap = "Local EONR vs Yield Selection Approach", fig.width = 4, fig.width = 6, dpi = 400, cache=FALSE}

selection_ranks <- readRDS(here::here("Shared/Results/Mona_results/selection_ranks.rds"))

# Create a visualization for Local EONR selection
local_eonr_plot <- selection_ranks[, .(N = sum(eonr_selected_gam)), by = method] %>%
  ggplot() +
  geom_bar(aes(y = N, x = method, fill = "Local EONR Selection"), stat = "identity", position = "dodge") +
  labs(x = "Methods", y = "Count", fill = "5 Folds, 5 Repeats") +
  theme_minimal()

# Create a visualization for Yield selection
yield_plot <- selection_ranks[, .(N = sum(yield_selected)), by = method] %>%
  ggplot() +
  geom_bar(aes(y = N, x = method, fill = "Yield Selection"), stat = "identity", position = "dodge") +
  labs(x = "Methods", y = "Count", fill = "5 Folds, 5 Repeats") +
  theme_minimal()

# Combine the two plots 
combined_plot <- local_eonr_plot + 
  geom_bar(aes(y = N, x = method, fill = "Yield Selection"), 
           data = selection_ranks[, .(N = sum(yield_selected)), by = method], 
           stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("Yield Selection" = "#999999", "Local EONR Selection" = "#333333")) +
  labs(fill = "Selection Type") +
  theme_minimal()+
   theme(legend.text = element_text(size = 8),    # Adjust the legend text size
        legend.title = element_text(size = 10),
        axis.text.x = element_text(size = 6))


# Display the combined plot
print(combined_plot)


```
Figure \@ref(fig:fig-4) presents an illustrative representation of two model selection process, encompassing both local EONR and yield prediction criteria. On the X-axis, we depict the candidate ML models. For the local EONR selection approach, the Y-axis displays the frequency of model selection concerning the comparison to EONRs estimated by the GAM. In the context of yield selection, the Y-axis illustrates the frequency of model preference based on its accuracy in yield prediction.

Among these models, the SE model emerged as the frontrunner, displaying the lowest RMSE in approximately 70.2% of simulations compared to the true EONR, demonstrating accurate EONR estimation. Following closely, the linear model exhibited strong performance, achieving the lowest RMSE in about 17% of simulations. The CF model ranked next, with the lowest RMSE for true EONR in about 10.8% of simulations. Conversely, the BRF model displayed lower accuracy, as indicated by the lowest RMSE in only 2% of simulations.

These results underscore a consistent alignment between the ranking of estimated local EONRs and the ranking of site-specific estimated EONRs, which serves as the baseline. This reinforces the robustness of utilizing local EONR estimation for ranking ML models, substantially enhancing the probability of selecting the optimal one.

Transitioning to the yield selection method, the BRF model consistently exhibited the lowest RMSE in relation to the true yield in approximately 99.2% of simulations. Following the BRF model, the linear model demonstrated the lowest RMSE in a minority of simulations, accounting for around 0.8% when compared to the true yield.


These findings emphasize the predictive strength of the BRF model for yield estimation during model selection. However, it's important to acknowledge that the true ML model in predicting EONR is, in fact, the SE model. Notably, if yield were the sole criterion, the BRF model would be favored.

In essence, these findings underscore the potential viability of employing cross-validation for EONR as a promising model selection approach. As highlighted in the study by Kakimoto et al. (2022), this could be attributed to the detachment between EONR prediction and yield prediction. Consequently, relying on yield prediction accuracy for model selection might not be as advantageous when the primary objective is to predict EONR. The study further suggests that yield prediction accuracy should not be the sole criterion for model selection.


## Diminished accuracy and economic performance 


```{r fig.id = "fig-5", fig.cap = "Performance Loss Compared to the True Best Model", fig.width = 4, fig.width = 6, dpi = 400, cache=FALSE}

comp_results <-
  readRDS(here::here("Shared/Results/comp_results.rds")) %>%
  data.table()

perf_loss_data <-
  comp_results[, .(num_folds, num_repeats, loss_data)] %>%
  unnest(loss_data) %>%
  data.table()

perf_loss_data_eonr <-
  perf_loss_data[, .(sim, num_folds, num_repeats, e_rmse_eonr_loss, y_rmse_eonr_loss)] %>%
  melt(id.var = c("sim", "num_folds", "num_repeats")) %>%
  .[, selection := case_when(
    variable == "e_rmse_eonr_loss" ~ "LEONR-based Selection",
    variable == "y_rmse_eonr_loss" ~ "Yield-based Selection"
  )]

(
  ggplot(perf_loss_data_eonr[num_folds == 5 & num_repeats == 5, ]) +
    geom_histogram(aes(x = value)) +
    facet_grid(selection ~ .) +
    theme_bw()
)
```

```{r fig.id = "fig-6", fig.cap = "Profit Loss Compared to the True Best Model", fig.width = 4, fig.width = 6, dpi = 400, cache=FALSE}
perf_loss_data_pi <-
  perf_loss_data[, .(sim, num_folds, num_repeats, e_pi_loss, y_pi_loss)] %>%
  melt(id.var = c("sim", "num_folds", "num_repeats")) %>%
  .[, selection := case_when(
    variable == "e_pi_loss" ~ "LEONR-based Selection",
    variable == "y_pi_loss" ~ "Yield-based Selection"
  )]

(
  ggplot(perf_loss_data_pi[num_folds == 5 & num_repeats == 5, ]) +
    geom_histogram(aes(x = value)) +
    facet_grid(selection ~ .) +
    theme_bw()
)
```


```{r, tab.id = "table_1", tab.cap = "Averaged Performance and Profit Loss"}
#knitr::include_graphics(here::here("Loss.jpg"))
#knitr::include_graphics(file.path("/Users/mmousavi2/Dropbox/Local-Cross-Validation", "Loss.jpg"))

```
<br>
<br>
<br>

![Averaged Performance and Profit Loss](/Users/mmousavi2/Dropbox/Local-Cross-Validation/Loss.jpg){width=70%}




It's crucial to gauge the impact on performance and profit when using our suggested model through our local EONR selection method. We've shown this contrast in Figures \@ref(fig:fig-5) and \@ref(fig:fig-6), which illustrate differences in how well the model predicts site-specific EONR and the resulting profits.

The vertical lines in these figures represent how often a model leads to a certain level of performance or profit loss compared to the most accurate ML model across 500 simulations. Clearly, choosing the model based on yield prediction accuracy results in poorer performance and lower profits compared to the Local cross validation approach.

These findings are summarized in Table 1, which shows average performance and profit changes for both our local EONR and yield prediction methods. When using the yield prediction method, performance worsens by 6.70, and profits decrease by 12.13. On the other hand, the local EONR selection approach leads to much smaller performance loss (1.51) and only a minor profit reduction (2.47). This demonstrates that the local EONR approach is a better choice compared to the yield prediction method in terms of maintaining performance and profitability.


## The impact of different fold repeat combination on local EONR selection and yield selection method

```{r fig.id = "fig-7", fig.cap = "The impact of different fold repeat combinations\non local EONR and yield selection method", fig.width = 4, fig.width = 6, dpi = 400, cache=FALSE}
perf_ranking_e <-
  comp_results[, .(num_folds, num_repeats, selection_perf_rank_LE)] %>%
  unnest(selection_perf_rank_LE) %>%
  data.table()

perf_ranking_y <-
  comp_results[, .(num_folds, num_repeats, selection_perf_rank_Y)] %>%
  unnest(selection_perf_rank_Y) %>%
  data.table()

# Add a new column "Type" to distinguish between 'e' and 'y'
perf_ranking_e$Selection_Type <- "Local EONR Selection"
perf_ranking_y$Selection_Type <- "Yield Selection"

# Merge the two data frames into one
perf_ranking_combined <- rbind(perf_ranking_e, perf_ranking_y)

# Plot the combined data using dodge position and refined colors
ggplot(perf_ranking_combined) +
  geom_bar(aes(y = N, x = eonr_rank_true, fill = Selection_Type), stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("Local EONR Selection" = "#333333", "Yield Selection" = "#999999")) +  # Set colors
  facet_grid(num_folds ~ num_repeats) +
  labs(
    x = "True EONR Rank",
    y = "Count",
    fill = "Selection Type"
  ) +
  theme_minimal()

```
Figure \@ref(fig:fig-7) presents a comparison of two model selection criteria: local EONR and yield-based, across various combinations of folds and repeats. The x-axis represents the ranking of the true EONR, with rank 1 indicating the best-performing ML model in estimating EONRs.

In the context of local EONR model selection, the y-axis depicts the frequency of correct model selection. The local EONR criterion consistently demonstrated an increasing trend in accuracy as the number of folds and repeats increased. For example, with 5 folds and 1 repeat, the correct model was selected in approximately 57.2 percent of simulations. This success rate improved to 58.4 percent with 5 repeats, and further to 62.4 percent with 7 folds and 5 repeats. Notably, increasing the number of folds to 10 while maintaining 5 repeats resulted in a substantial improvement, achieving a success rate of 65.8 percent. The pattern continued across different combinations, such as 5 folds and 10 repeats (59.4 percent success) and 10 folds and 10 repeats (65.2 percent success). This consistent improvement in accuracy underscores the positive impact of increasing the number of folds and repeats on the local EONR model selection.

Contrastingly, yield-based model selection exhibited a lower success rate in identifying the best-performing model for EONR estimation. Across all combinations of folds and repeats, the yield-based method consistently achieved a success rate of approximately 14.2-14.4 percent. This low success rate remained largely unaffected by variations in the number of folds and repeats. Consequently, it can be inferred that altering the fold and repeat parameters did not significantly influence the performance of the yield-based model selection in accurately identifying the optimal model for EONR estimation.

In summary, the findings from these two model selection criteria highlight a clear distinction in their responses to different combinations of folds and repeats. While the local EONR criterion exhibited a notable increase in accuracy as folds and repeats were increased, the yield-based model selection method consistently demonstrated limited effectiveness across all scenarios. These insights shed light on the impact of fold and repeat variations on the performance of model selection criteria for EONR estimation.

## Correlation Between GAM-Estimated EONR and True EONR

```{r fig.id = "fig-8", fig.cap = "GAM vs True EONR", fig.width = 4, fig.width = 6, dpi = 400, cache=FALSE}

gam_results_dif_combination <- readRDS(here::here("Shared/Results/Mona_results/gam_results_dif_combination.rds")) %>% data.table()

gam_true <-
  gam_results_dif_combination[, .(num_folds, num_repeats, comb)] %>%
  unnest(comb) %>%
  data.table()


gam_true_vis <- ggplot(gam_true, aes(x= opt_N, y= opt_N_gam)) +
  geom_point(colour= I("#999999"))+
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  xlim(50 , 300) +
  ylim(50 , 300)+
  facet_grid(num_folds ~ num_repeats)

gam_true_vis <- gam_true_vis + facet_wrap(num_folds ~ num_repeats)

gam_true_vis
```
Figure \@ref(fig:fig-8) depicts the correlation between the true EONRs and the gam estimated local EONRs. The analysis considers multiple combinations of folds and repeats. Notably, a robust and consistent association is observed between the GAM-estimated local EONRs and the true EONRs, regardless of the specific number of folds and repeats utilized. This finding suggests that the estimated local EONRs derived from the GAM serve as a reliable proxy for the true EONRs. A GAM is a sophisticated statistical approach that goes beyond traditional linear models, permitting the modeling of non-linear connections between predictors and the response variable. Unlike linear models, GAMs have the capacity to uncover flexible relationships within the data. They achieve this by independently modeling the impact of each predictor on the response, resulting in an additive structure that excels at capturing intricate relationships, particularly in cases of intricate predictor interactions. Moreover, GAMs often employ advanced smoothing techniques, such as spline functions, to estimate these non-linear relationships. These smoothing techniques are adept at reducing noise within the data and revealing underlying patterns, ultimately leading to enhanced predictive accuracy. Another factor that strengthens GAM's role as a viable stand-in for true EONRs is our thorough model tuning and validation process, which reinforces the model's reliability and performance.

## Visual Comparison: Average GAM EONR vs. Average Local EONR  

```{r fig.id = "fig-9", fig.cap = "Average GAM EONR vs. Average Local EONR", fig.width = 4, fig.width = 6, dpi = 400, cache=FALSE}

sum_results_gam<- readRDS(here::here("Shared/Results/Mona_results/sum_results_gam.rds"))
main_sum_results <- readRDS(here::here("Shared/Results/Mona_results/main_sum_results.rds"))

# combined results other version 
combined_results_other_v <-
  sum_results_gam[main_sum_results, on = c("sim", "split_id")] %>%
  .[, opt_N_dif_select := opt_N_hat - opt_N_gam]


# Group the data by "sim" and "method" columns, and calculate the average of "opt_N_hat" and "opt_N"
averaged_df <- combined_results_other_v %>%
  group_by(sim, method) %>%
  summarize(avg_opt_N_hat = mean(opt_N_hat),
            avg_opt_N_gam = mean(opt_N_gam))



# Create separate graphs by method using facet_wrap
ggplot(averaged_df, aes(x = avg_opt_N_gam, y = avg_opt_N_hat)) +
  geom_point(color = "#999999") +  # Set points to dark gray
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  scale_x_continuous(limits = c(100, 180)) +
  scale_y_continuous(limits = c(100, 180)) +
  labs(x = "Average GAM EONR", y = "Average Local EONR") +
  facet_wrap(~ method, ncol = 2)

```
Figure \@ref(fig:fig-9) depicts the relationship between the average GAM estimated local EONRs and the average local EONRs estimated by candidate ML models, considering 5 folds and 5 repeats for all simulations. It is evident from the plot that both the RF and BRF models consistently underestimate the gam EONRs.
The consistent underestimation of GAM EONRs by RF and BRF models could be due to their difficulties in capturing intricate spatial patterns and dependencies, which the GAM model handles effectively. The GAM's spatial error structure more accurately represents nuanced relationships between variables, preventing overfitting and resulting in more realistic estimates. 
Analyzing figure \@ref(fig:fig-9) reveals that models such as BRF or RF might excel in prediction, but evidently fall short in estimating EONR. Conversely, models like SE, linear, or CF significantly outperform in EONR estimation. They likely exhibit strong performance due to their ability to capture complex relationships, spatial dependencies, and causal links within the data.


## Assessing Accuracy in Yield-Based Model Selection: RMSE of Yield and RMSE of True EONR"

```{r fig.id = "fig-10", fig.cap = "RMSE of Yield vs. RMSE of True EONR", fig.width = 4, fig.width = 6, dpi = 400, cache=FALSE}
# Group the data by "sim" and "method" columns, and calculate the average of "rmse of yield" and "rmse of yield"
averaged_df <- main_sum_results %>%
  group_by(sim, method) %>%
  summarize(avg_rmse_eonr_true = mean(rmse_eonr_true),
            avg_rmse_yield = mean(rmse_yield))

# Create separate graphs by method using facet_wrap
ggplot(averaged_df, aes(x = avg_rmse_yield, y = avg_rmse_eonr_true)) +
  geom_point(color = "#999999") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  #scale_x_continuous(limits = c(100, 180)) +
  #scale_y_continuous(limits = c(100, 180)) +
  labs(x = "RMSE of Yield", y = "RMSE of true EONR") +
  facet_wrap(~ method, ncol = 2)

```

Figure \@ref(fig:fig-10) illustrates the relationship between the RMSE values of yield and the RMSE values of true EONRs across all simulations and candidate ML models (excluding the CF model which doesn't estimate yield). The figure emphasizes that there are instances where the RMSE of the true EONR is the lowest, while the RMSE of yield prediction is the highest, and vice versa.

This finding highlights the potential occurrence of cases where the accuracy of EONR estimation and yield prediction may not align. In some situations, even if the RMSE of the true EONR is minimized, the RMSE of yield prediction may be relatively higher. Similarly, there are cases where the RMSE of yield prediction is minimized while the RMSE of the true EONR may not be at its lowest. These results indicate a decoupling between the accuracy of EONR estimation and yield prediction in certain instances.


# Conclusion
           
In conclusion, our study introduced a new approach for predicting site-specific Economic Optimal Nitrogen Rate (EONR) using machine learning models. Traditional methodologies have often relied on selecting models based on their performance in predicting yield, assuming that such models would also excel in predicting EONR. However, our research demonstrated that this approach does not necessarily lead to accurate EONR predictions. Through the application of our proposed local EONR prediction method, utilizing cross-validation with EONR data rather than yield, we achieved rankings of machine learning models that closely aligned with the true rankings for site-specific EONR prediction.

The comparison between rankings based on yield prediction accuracy and our local EONR prediction approach revealed a significant discrepancy. Models that excelled in yield prediction did not consistently perform well in predicting EONR accurately. This emphasizes the limitations of relying solely on yield-based model selection for EONR estimation.

Moreover, our study quantified the economic implications of model selection criteria. The difference in profit between selecting models based on yield prediction versus local EONR prediction was substantial, with an average profit loss of 12.13 dollars per kilogram for the former compared to only $2.47 per kilogram for the latter. Additionally, we observed performance losses of 6.7 on average when utilizing yield-based selection and only 1.51 on average when employing our local EONR prediction approach.

In essence, our findings underscore the significance of tailored model selection strategies for accurate EONR prediction. The local EONR prediction method we introduced not only achieves predictions closely aligned with true rankings but also leads to more economically sound decisions in nitrogen management. This research highlights the importance of considering the specific target variable when selecting machine learning models for agronomic decision-making, offering a valuable contribution to the field of precision agriculture.


 
`r run_pagebreak()` 
























       





<!--
# /*===========================================================
#' # References
# /*===========================================================
-->

# References



<div id="refs"></div>

\newpage

# Figures {-}

# Appendix {-}

#```{r, child = "appendix.rmd"}
#```

